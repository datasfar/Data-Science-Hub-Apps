{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "# ¿Porqué ponemos esta linea? https://github.com/tensorflow/datasets/issues/3918\n",
    "setattr(tfds.image_classification.cats_vs_dogs, '_URL', \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")\n",
    "\n",
    "# Verificar que la URL se ha modificado correctamente\n",
    "print(tfds.image_classification.cats_vs_dogs._URL)\n",
    "\n",
    "# Descargar el set de datos de perros y gatos\n",
    "datos, metadatos = tfds.load('cats_vs_dogs', as_supervised=True, with_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El código arrojaba error de recursividad al cargar el dataset. \n",
    "# Solución: Utilizar entorno virtual\n",
    "# Python 3.11.0\n",
    "# Tensorflow 2.15.0\n",
    "# Tensorflow Datasets 4.9.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos los metadatos del dataset\n",
    "metadatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencias para mostrar imagenes del dataset\n",
    "# pip install pandas\n",
    "# pip install Jinja2\n",
    "# pip install pillow\n",
    "# pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una forma de mostrar 5 ejemplos del set\n",
    "tfds.as_dataframe(datos['train'].take(5), metadatos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra forma de mostrar ejemplos del set\n",
    "tfds.show_examples(datos['train'], metadatos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias para modificar imagenes\n",
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipular y visualizar el set\n",
    "# Lo pasamos a TAMANO_IMG (100x100) y a blanco y negro (solo para visualizar)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "TAMANO_IMG=100\n",
    "\n",
    "for i, (imagen, etiqueta) in enumerate(datos['train'].take(25)):\n",
    "  imagen = cv2.resize(imagen.numpy(), (TAMANO_IMG, TAMANO_IMG))\n",
    "  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "  plt.subplot(5, 5, i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.imshow(imagen, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable que contendra todos los pares de los datos (imagen y etiqueta) ya modificados (blanco y negro, 100x100)\n",
    "datos_entrenamiento = []\n",
    "\n",
    "for i, (imagen, etiqueta) in enumerate(datos['train']): #Todos los datos\n",
    "  imagen = cv2.resize(imagen.numpy(), (TAMANO_IMG, TAMANO_IMG))\n",
    "  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "  imagen = imagen.reshape(TAMANO_IMG, TAMANO_IMG, 1) #Cambiar tamano a 100,100,1\n",
    "  datos_entrenamiento.append([imagen, etiqueta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver los datos del primer indice\n",
    "datos_entrenamiento[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver cuantos datos tengo en la variable\n",
    "len(datos_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparar mis variables X (entradas) y y (etiquetas) separadas\n",
    "\n",
    "X = [] #imagenes de entrada (pixeles)\n",
    "y = [] #etiquetas (perro o gato)\n",
    "\n",
    "for imagen, etiqueta in datos_entrenamiento:\n",
    "  X.append(imagen)\n",
    "  y.append(etiqueta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X\n",
    "#Normalizar los datos de las X (imagenes). Se pasan a numero flotante y dividen entre 255 para quedar de 0-1 en lugar de 0-255\n",
    "import numpy as np\n",
    "\n",
    "X = np.array(X).astype(float) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y\n",
    "#Convertir etiquetas en arreglo simple\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear los modelos iniciales\n",
    "#Usan sigmoid como salida (en lugar de softmax) para mostrar como podria funcionar con dicha funcion de activacion.\n",
    "#Sigmoid regresa siempre datos entre 0 y 1. Realizamos el entrenamiento para al final considerar que si la respuesta se\n",
    "#acerca a 0, es un gato, y si se acerca a 1, es un perro.\n",
    "\n",
    "modeloDenso = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(100, 100, 1)),\n",
    "  tf.keras.layers.Dense(150, activation='relu'),\n",
    "  tf.keras.layers.Dense(150, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilar modelos. Usar crossentropy binario ya que tenemos solo 2 opciones (perro o gato)\n",
    "modeloDenso.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La variable de tensorboard se envia en el arreglo de \"callbacks\" (hay otros tipos de callbacks soportados)\n",
    "#En este caso guarda datos en la carpeta indicada en cada epoca, de manera que despues\n",
    "#Tensorboard los lee para hacer graficas\n",
    "tensorboardDenso = TensorBoard(log_dir='logs/denso')\n",
    "modeloDenso.fit(X, y, batch_size=32,\n",
    "                validation_split=0.15,\n",
    "                epochs=100,\n",
    "                callbacks=[tensorboardDenso])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorboard tensorboardX\n",
    "\n",
    "# Ejecutando el siguiente comando en terminal generamos un server con tensorboard y los datos del entrenamiento\n",
    "# tensorboard --logdir=logs/denso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estado actual:\n",
    "- Dataset cargado.\n",
    "- Muestreo de datos de ejemplo graficados.\n",
    "- Creación del modelo \"Denso\" \n",
    "- Entrenamiento del modelo \"Denso\"\n",
    "- Visualización de los datos de entrenamiento del modelo \"Denso\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Que vamos a hacer:\n",
    "- Ampliar los datos de entreno con nuevos datos generados.\n",
    "- Crear un nuevo modelo\n",
    "- Entrenarlo añadiendo los datos generados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora vamos a generar un aumento de datos para tener datos de entrenamiento más diversos\n",
    "# Realizar el aumento de datos con varias transformaciones. Al final, graficar 10 como ejemplo\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=15,\n",
    "    zoom_range=[0.7, 1.4],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "datagen.fit(X)\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "for imagen, etiqueta in datagen.flow(X, y, batch_size=10, shuffle=False):\n",
    "  for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(imagen[i].reshape(100, 100), cmap=\"gray\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura de la red neuronal para entrenamiento con aumento de datos\n",
    "modeloCNN_AD = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(100, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloCNN_AD.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar los datos de entrenamiento y los datos de pruebas en variables diferentes\n",
    "\n",
    "len(X) * .85 #19700\n",
    "len(X) - 19700 #3562\n",
    "\n",
    "X_entrenamiento = X[:19700]\n",
    "X_validacion = X[19700:]\n",
    "\n",
    "y_entrenamiento = y[:19700]\n",
    "y_validacion = y[19700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usar la funcion flow del generador para crear un iterador que podamos enviar como entrenamiento a la funcion FIT del modelo\n",
    "data_gen_entrenamiento = datagen.flow(X_entrenamiento, y_entrenamiento, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboardCNN_AD = TensorBoard(log_dir='logs-new/cnn_AD')\n",
    "\n",
    "modeloCNN_AD.fit(\n",
    "    data_gen_entrenamiento,\n",
    "    epochs=150, batch_size=32,\n",
    "    validation_data=(X_validacion, y_validacion),\n",
    "    steps_per_epoch=int(np.ceil(len(X_entrenamiento) / float(32))),\n",
    "    validation_steps=int(np.ceil(len(X_validacion) / float(32))),\n",
    "    callbacks=[tensorboardCNN_AD]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloCNN_AD.save('perros-gatos-cnn-ad.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
